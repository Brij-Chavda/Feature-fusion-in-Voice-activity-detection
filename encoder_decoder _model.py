# -*- coding: utf-8 -*-
"""Encoder-Decoder

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SMYLE7cKWEVsNEQDY3LnXT2kMZlccJgq
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import LSTMCell
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import InputLayer
from tensorflow.keras import Input
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.layers import Attention
from tensorflow.keras.layers import GlobalAveragePooling1D
from tensorflow.keras.layers import AdditiveAttention
from tensorflow.keras.layers import Reshape
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import TimeDistributed
from sklearn.metrics import roc_curve
from scipy.optimize import brentq
from scipy.interpolate import interp1d

import numpy as np
from sklearn.preprocessing import StandardScaler
def preprocessing(n_feature):
  import pickle
  filename = '/content/drive/My Drive/noisyXtrwithoutnorm' + str(n_feature) +'all.pkl'
  with open(filename, 'rb') as f:
    Xtr = pickle.load(f)
  import pickle
  filename = '/content/drive/My Drive/clean' + str(n_feature) + 'Xvalwithoutnorm.pkl'
  with open(filename, 'rb') as f:
    Xval = pickle.load(f)
  import pickle
  filename = '/content/drive/My Drive/clean' + str(n_feature) + 'Xtestwithoutnorm.pkl'
  with open(filename, 'rb') as f:
    Xtest = pickle.load(f)

  with open('/content/drive/My Drive/withendinglabel_seg.pkl', 'rb') as f:
    Ytr = pickle.load(f)
  with open('/content/drive/My Drive/withendingvallabel_seg.pkl', 'rb') as f:
    Yval = pickle.load(f)
  with open('/content/drive/My Drive/withendingtestlabel_seg.pkl', 'rb') as f:
    Ytest = pickle.load(f)
  tr_shape = np.shape(Xtr[1,:])
  test_shape = np.shape(Xtest[1,:])
  val_shape = np.shape(Xval[1,:])
  for i in range(36):
    scaler = StandardScaler()
    scaler.fit(Xtr[i,:].reshape(-1,1))
    print(scaler.mean_)
    Xtr[i,:] = np.reshape(scaler.transform(Xtr[i,:].reshape(-1,1)), tr_shape)
    Xtest[i,:] = np.reshape(scaler.transform(Xtest[i,:].reshape(-1,1)), test_shape)
    Xval[i,:] = np.reshape(scaler.transform(Xval[i,:].reshape(-1,1)), val_shape)
  feature_xtrain = []
  feature_xtest = []
  feature_xval = []
  feature_ytrain = []
  feature_ytest = []
  feature_yval = []

  Xtr = np.transpose(Xtr)
  n_segment = 13989
  for n in range(n_segment):
      if n == 0:
          st = 0
          en = 100
      else:
          st = (n-1)*100
          en = n * 100

      feature_xtrain.append(Xtr[st:en, :])
      feature_ytrain.append(Ytr[st:en])
  print(np.shape(feature_xtrain))
  Xtest = np.transpose(Xtest)
  feature_ytest = []
  feature_yval = []
  feature_xtest = []
  feature_xval = []
  n_segment = int(len(Xtest) / 100)
  for n in range(n_segment):
      if n == 0:
          st = 0
          en = 100
      else:
          st = (n-1)*100
          en = n * 100

      feature_xtest.append(Xtest[st:en, :])
      feature_ytest.append(Ytest[st:en])
      
  print(np.shape(feature_xtest))
  Xval = np.transpose(Xval)
  n_segment = int(len(Xval) / 100)

  for n in range(n_segment):
      if n == 0:
          st = 0
          en = 100
      else:
          st = (n-1)*100
          en = n * 100

      feature_xval.append(Xval[st:en, :])
      feature_yval.append(Yval[st:en])
  print(np.shape(feature_xval))
  from sklearn.utils import shuffle
  feature_xtrain, feature_ytrain = shuffle(feature_xtrain, feature_ytrain)
  feature_xtrain = np.array(feature_xtrain)
  feature_ytrain = np.array(feature_ytrain)
  feature_xval = np.array(feature_xval)
  feature_yval = np.array(feature_yval)
  feature_xtest = np.array(feature_xtest)
  feature_ytest = np.array(feature_ytest)
  return feature_xtrain, feature_ytrain, feature_xval, feature_yval, feature_xtest, feature_ytest

import tensorflow as tf
import os
from tensorflow.python.keras.layers import Layer
from tensorflow.python.keras import backend as K


class AttentionLayer(Layer):
    """
    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).
    There are three sets of weights introduced W_a, U_a, and V_a
     """

    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        assert isinstance(input_shape, list)
        # Create a trainable weight variable for this layer.

        self.W_a = self.add_weight(name='W_a',
                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),
                                   initializer='uniform',
                                   trainable=True)
        self.U_a = self.add_weight(name='U_a',
                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),
                                   initializer='uniform',
                                   trainable=True)
        self.V_a = self.add_weight(name='V_a',
                                   shape=tf.TensorShape((input_shape[0][2], 1)),
                                   initializer='uniform',
                                   trainable=True)

        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end

    def call(self, inputs, verbose=False):
        """
        inputs: [encoder_output_sequence, decoder_output_sequence]
        """
        assert type(inputs) == list
        encoder_out_seq, decoder_out_seq = inputs
        if verbose:
            print('encoder_out_seq>', encoder_out_seq.shape)
            print('decoder_out_seq>', decoder_out_seq.shape)

        def energy_step(inputs, states):
            """ Step function for computing energy for a single decoder state
            inputs: (batchsize * 1 * de_in_dim)
            states: (batchsize * 1 * de_latent_dim)
            """

            assert_msg = "States must be an iterable. Got {} of type {}".format(states, type(states))
            assert isinstance(states, list) or isinstance(states, tuple), assert_msg

            """ Some parameters required for shaping tensors"""
            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]
            de_hidden = inputs.shape[-1]

            """ Computing S.Wa where S=[s0, s1, ..., si]"""
            # <= batch size * en_seq_len * latent_dim
            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)

            """ Computing hj.Ua """
            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim
            if verbose:
                print('Ua.h>', U_a_dot_h.shape)

            """ tanh(S.Wa + hj.Ua) """
            # <= batch_size*en_seq_len, latent_dim
            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)
            if verbose:
                print('Ws+Uh>', Ws_plus_Uh.shape)

            """ softmax(va.tanh(S.Wa + hj.Ua)) """
            # <= batch_size, en_seq_len
            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)
            # <= batch_size, en_seq_len
            e_i = K.softmax(e_i)

            if verbose:
                print('ei>', e_i.shape)

            return e_i, [e_i]

        def context_step(inputs, states):
            """ Step function for computing ci using ei """

            assert_msg = "States must be an iterable. Got {} of type {}".format(states, type(states))
            assert isinstance(states, list) or isinstance(states, tuple), assert_msg

            # <= batch_size, hidden_size
            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)
            if verbose:
                print('ci>', c_i.shape)
            return c_i, [c_i]

        fake_state_c = K.sum(encoder_out_seq, axis=1)
        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim

        """ Computing energy outputs """
        # e_outputs => (batch_size, de_seq_len, en_seq_len)
        last_out, e_outputs, _ = K.rnn(
            energy_step, decoder_out_seq, [fake_state_e],
        )

        """ Computing context vectors """
        last_out, c_outputs, _ = K.rnn(
            context_step, e_outputs, [fake_state_c],
        )

        return c_outputs, e_outputs

    def compute_output_shape(self, input_shape):
        """ Outputs produced by the layer """
        return [
            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),
            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))
        ]

from tensorflow.keras.layers import Concatenate
reg = l2(l=0.01)
#n_feature = 54
def create_model(n_feature):

    encoder_input = Input(shape = (100,n_feature))
    decoder_input = Input(shape = (101,1))
    encoder_layer = Bidirectional(LSTM(25, return_sequences = True, return_state = True, kernel_regularizer=reg, name = 'encoder_layer'))
    lstm_layer, h_state, c_state, h_state1, c_state1 = encoder_layer(encoder_input)
    h = Concatenate()([h_state, h_state1])
    c = Concatenate()([c_state, c_state1])
    en_states = [h,c]

    #decoder
    decoder_layer = (LSTM(50, return_sequences = True, return_state = True, kernel_regularizer=reg, name = 'decoder_layer'))
    decoder_lstm, decode_h_state, decode_c_state = decoder_layer(decoder_input, initial_state = en_states)

    #attention
    attn_layer = AttentionLayer(name = 'attention_layer')
    attn_out, attn_states = attn_layer([lstm_layer, decoder_lstm])
    decoder_concat_input = tf.keras.layers.Concatenate(axis = -1, name='concat_layer')([decoder_lstm, attn_out])
    output_layer = TimeDistributed(Dense(1, activation = 'sigmoid'))
    pred = output_layer(decoder_concat_input)

    #full model
    model = tf.keras.Model(inputs = [encoder_input, decoder_input], outputs = pred)
    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

    batch_size = 1
    #Inference_model
    encoder_inf_inputs = Input(batch_shape=(batch_size, 100, n_feature), name='encoder_inf_inputs')
    Infl3,i_h,i_c,i_h1,i_c1 = encoder_layer(encoder_inf_inputs)
    Inf_h = Concatenate()([i_h, i_h1])
    Inf_c = Concatenate()([i_c, i_c1])
    encoder_model = tf.keras.Model(inputs=encoder_inf_inputs, outputs=[Infl3, Inf_h, Inf_c])


    decoder_inf_inputs = Input(batch_shape=(batch_size, 1, 1))
    encoder_inf_states = Input(batch_shape=(batch_size, 100, 50))
    decoder_state_input_h = Input(shape=(50,))
    decoder_state_input_c = Input(shape=(50,))

    decoder_inf_out, dec_h, dec_c = decoder_layer(decoder_inf_inputs, initial_state = [decoder_state_input_h, decoder_state_input_c])
    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])
    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])
    concat_reshape = tf.reshape(decoder_inf_concat, [batch_size,100])
    print(np.shape(concat_reshape))
    print(np.shape(decoder_inf_concat))
    decoder_inf_pred = output_layer(decoder_inf_concat)

    decoder_model = tf.keras.Model(inputs =  [encoder_inf_states,decoder_state_input_h, decoder_state_input_c, decoder_inf_inputs], outputs=[decoder_inf_pred, attn_inf_states, dec_h, dec_c])

    return model, decoder_model, encoder_model

def Inf(encoder_model, decoder_model, test_seq, n_feature):
    enc_outs, enc_h, enc_c = encoder_model.predict(test_seq)
    dec_h = enc_h
    dec_c = enc_c
    #ec_state = enc_last_state
    attention_weights = []
    a = [2]
    test_seq = np.expand_dims(a,1)  #sod
    output = []
    prediction = []
    for i in range(100):
        dec_out, attention, dec_h, dec_c = decoder_model.predict([enc_outs, dec_h, dec_c, test_seq])
        dec_ind = [1 if dec_out > 0.5 else 0]
        test_seq = np.expand_dims(dec_ind,1)
        attention_weights.append((dec_ind, attention))
        output.append(dec_ind)
        prediction.append(dec_out)
    return output, attention_weights, prediction

#SOD, EOD addition
def seq_decoder(x):
  y_train= [[2] + [y_ for y_ in i] + [2] for i in x]
  y_train = np.array(y_train)
  return y_train

def train(full_model, en_seq, fr_seq, batch_size, n_epochs=50):
    """ Training the model """

    for ep in range(n_epochs):
        losses = []
        for bi in range(0, en_seq.shape[0], batch_size):
            encoder_input = en_seq[bi:bi + batch_size, :]
            target_label = fr_seq[bi:bi + batch_size, :]

            full_model.train_on_batch([encoder_input, target_label[:, :-1]], target_label[:, 1:])

            l = full_model.evaluate([encoder_input, target_label[:, :-1]], target_label[:, 1:],
                                    batch_size=batch_size, verbose=0)

            losses.append(l)
        print("Loss in epoch {}: {}".format(ep + 1, np.mean(losses)))

for i in [36,54,72]:
  feature_xtrain, feature_ytrain, feature_xval, feature_yval, feature_xtest, feature_ytest = preprocessing(i)
  feature_ytrain = seq_decoder(feature_ytrain)
  feature_yval = seq_decoder(feature_yval)
  feature_ytest = seq_decoder(feature_ytest)
  model, decoder_model, encoder_model = create_model(i)
  train(model, feature_xtrain, feature_ytrain, 128)
  out = []
  out_predict = []
  for i in range(len(feature_xtest)):
    feature = tf.reshape(feature_xtest[i],[1,100,i])
    temp_o, temp_w, predict = Inf(encoder_model, decoder_model, feature, i)
    out.append(temp_o)
    out_predict.append(predict)

  out_predict = np.reshape(out_predict, (325100, 1))
  Ytrue = np.reshape(feature_ytest, (325100, 1))
  fpr, tpr, threshold = roc_curve(Ytrue , out_predict, pos_label = 1)
  eer = brentq(lambda x : 1. -x -interp1d(fpr, tpr)(x), 0., 1.)
  thresh = interp1d(fpr, threshold)(eer)
  print(eer)
  print(thresh)