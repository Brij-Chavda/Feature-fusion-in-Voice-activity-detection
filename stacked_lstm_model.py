# -*- coding: utf-8 -*-
"""Stacked_lstm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1umOd0hhkdcRv50S0lzke8xTAliOSomu4
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import LSTMCell
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import InputLayer
from tensorflow.keras import Input
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.layers import Attention
from tensorflow.keras.layers import GlobalAveragePooling1D
from tensorflow.keras.layers import AdditiveAttention
from tensorflow.keras.layers import Reshape
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import TimeDistributed

import numpy as np
from sklearn.preprocessing import StandardScaler
def preprocessing(n_feature):
  import pickle
  filename = '/content/drive/My Drive/noisyXtrwithoutnorm' + str(n_feature) +'all.pkl'
  with open(filename, 'rb') as f:
    Xtr = pickle.load(f)
  import pickle
  filename = '/content/drive/My Drive/clean' + str(n_feature) + 'Xvalwithoutnorm.pkl'
  with open(filename, 'rb') as f:
    Xval = pickle.load(f)
  import pickle
  filename = '/content/drive/My Drive/clean' + str(n_feature) + 'Xtestwithoutnorm.pkl'
  with open(filename, 'rb') as f:
    Xtest = pickle.load(f)

  with open('/content/drive/My Drive/withendinglabel_seg.pkl', 'rb') as f:
    Ytr = pickle.load(f)
  with open('/content/drive/My Drive/withendingvallabel_seg.pkl', 'rb') as f:
    Yval = pickle.load(f)
  with open('/content/drive/My Drive/withendingtestlabel_seg.pkl', 'rb') as f:
    Ytest = pickle.load(f)
  tr_shape = np.shape(Xtr[1,:])
  test_shape = np.shape(Xtest[1,:])
  val_shape = np.shape(Xval[1,:])
  for i in range(36):
    scaler = StandardScaler()
    scaler.fit(Xtr[i,:].reshape(-1,1))
    print(scaler.mean_)
    Xtr[i,:] = np.reshape(scaler.transform(Xtr[i,:].reshape(-1,1)), tr_shape)
    Xtest[i,:] = np.reshape(scaler.transform(Xtest[i,:].reshape(-1,1)), test_shape)
    Xval[i,:] = np.reshape(scaler.transform(Xval[i,:].reshape(-1,1)), val_shape)
  feature_xtrain = []
  feature_xtest = []
  feature_xval = []
  feature_ytrain = []
  feature_ytest = []
  feature_yval = []

  Xtr = np.transpose(Xtr)
  n_segment = 13989
  for n in range(n_segment):
      if n == 0:
          st = 0
          en = 100
      else:
          st = (n-1)*100
          en = n * 100

      feature_xtrain.append(Xtr[st:en, :])
      feature_ytrain.append(Ytr[st:en])
  print(np.shape(feature_xtrain))
  Xtest = np.transpose(Xtest)
  feature_ytest = []
  feature_yval = []
  feature_xtest = []
  feature_xval = []
  n_segment = int(len(Xtest) / 100)
  for n in range(n_segment):
      if n == 0:
          st = 0
          en = 100
      else:
          st = (n-1)*100
          en = n * 100

      feature_xtest.append(Xtest[st:en, :])
      feature_ytest.append(Ytest[st:en])
      
  print(np.shape(feature_xtest))
  Xval = np.transpose(Xval)
  n_segment = int(len(Xval) / 100)

  for n in range(n_segment):
      if n == 0:
          st = 0
          en = 100
      else:
          st = (n-1)*100
          en = n * 100

      feature_xval.append(Xval[st:en, :])
      feature_yval.append(Yval[st:en])
  print(np.shape(feature_xval))
  from sklearn.utils import shuffle
  feature_xtrain, feature_ytrain = shuffle(feature_xtrain, feature_ytrain)
  feature_xtrain = np.array(feature_xtrain)
  feature_ytrain = np.array(feature_ytrain)
  feature_xval = np.array(feature_xval)
  feature_yval = np.array(feature_yval)
  feature_xtest = np.array(feature_xtest)
  feature_ytest = np.array(feature_ytest)
  return feature_xtrain, feature_ytrain, feature_xval, feature_yval, feature_xtest, feature_ytest

from tensorflow.keras.metrics import RootMeanSquaredError
reg = l2(l=0.01)
def create_model(n_feature):
    ip_layer = Input(shape = (100,n_feature))
    #ip_layer = Input(shape = (100,54))(input_shape)
    lstm_layer1 = (LSTM(50, return_sequences = True, input_shape = (100,n_feature), kernel_regularizer=reg))(ip_layer)
    lstm_layer2 = (LSTM(50, return_sequences = True, kernel_regularizer=reg))(lstm_layer1)
    lstm_layer3 = (LSTM(50, return_sequences = True, kernel_regularizer=reg))(lstm_layer2)
    lstm_layer4 = (LSTM(50, return_sequences = True, kernel_regularizer=reg))(lstm_layer3)
    output_layer = TimeDistributed(Dense(1, activation = "linear"))(lstm_layer4)
    model = tf.keras.Model(inputs = ip_layer, outputs = output_layer)
    model.compile(optimizer = 'adam', loss = rmse_loss, metrics = RootMeanSquaredError())
    return model

from sklearn.metrics import roc_curve
from scipy.optimize import brentq
from scipy.interpolate import interp1d
from tensorflow.keras.callbacks import ReduceLROnPlateau

for j in [36, 54, 72]:
  feature_xtrain, feature_ytrain, feature_xval, feature_yval, feature_xtest, feature_ytest = preprocessing(j)
  model = create_model(j)
  reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, min_lr = 0, mode = 'auto')
  history = model.fit(feature_xtrain, feature_ytrain, epochs = 35, batch_size = 150, validation_data=(feature_xval, feature_yval), callbacks=[reduce_lr])
  Ypredict = model.predict(np.array(feature_xtest))
  Ypredict = np.reshape(Ypredict, (325100, 1))
  for i in range(len(Ypredict)):
    Ypredict[i] = (0.5 * Ypredict[i] + 0.5)
  Ytrue = np.reshape(feature_ytest, (325100, 1))
  for i in range(len(Ytrue)):
    if Ytrue[i] == -1:
      Ytrue[i] = 0
  fpr, tpr, threshold = roc_curve(Ytrue , Ypredict, pos_label = 1)
  eer = brentq(lambda x : 1. -x -interp1d(fpr, tpr)(x), 0., 1.)
  thresh = interp1d(fpr, threshold)(eer)
  print(eer)
  print(thresh)